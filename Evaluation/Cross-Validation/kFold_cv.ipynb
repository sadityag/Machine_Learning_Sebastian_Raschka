{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5293eb2f",
   "metadata": {},
   "source": [
    "$k$-fold cross validation is a robust way to handle cross validation. First, do a train-test split. Then, split the training data into $k$ different parts.  A model is then trained (from scratch), $k$ times, with the $i^{th}$ time training on all but the $i^{th}$ subset. This hold out is used for evaluation. The total evaluation score is the average of all $k$ evaluations of the $k$ trainings of the model. Do this for all models of interest (or for each set of hyperparameters to test). Once the best one is found, the best model (by average eval score) is then retrained from scratch on the entirety of the training set.\n",
    "\n",
    "A special case of this for small datasets is LOOCV (Leave One Out Cross Validation). If you have $n$ datapoints in your training set, this would be an $n$ fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba92602",
   "metadata": {},
   "source": [
    "A good standard value for k in k-fold cross-validation is 10, as empirical evidence shows. For instance, \n",
    "experiments by Ron Kohavi on various real-world datasets suggest that 10-fold cross-validation offers \n",
    "the best tradeoff between bias and variance (A Study of Cross-Validation and Bootstrap for Accuracy Estiï¿¾mation and Model Selection by Kohavi, Ron, International Joint Conference on Artificial Intelligence (IJCAI), 14 (12): 1137-43, 1995, https://www.ijcai.org/Proceedings/95-2/Papers/016.pdf).\n",
    "\n",
    "-- Sebastian Raschka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5785220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061e5d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "# Breast cancer data, with diagnosis as target variable\n",
    "print(df.loc[:, 1].value_counts())\n",
    "\n",
    "y = df.loc[:, 1].values\n",
    "X = df.loc[:, 2:].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th fold with class distribution [240 143].\n",
      "Accuracy: 0.977.\n",
      "2th fold with class distribution [240 143].\n",
      "Accuracy: 0.977.\n",
      "3th fold with class distribution [240 143].\n",
      "Accuracy: 0.907.\n",
      "4th fold with class distribution [240 143].\n",
      "Accuracy: 0.953.\n",
      "5th fold with class distribution [240 143].\n",
      "Accuracy: 0.977.\n",
      "6th fold with class distribution [240 143].\n",
      "Accuracy: 0.907.\n",
      "7th fold with class distribution [240 144].\n",
      "Accuracy: 0.929.\n",
      "8th fold with class distribution [241 143].\n",
      "Accuracy: 0.929.\n",
      "9th fold with class distribution [241 143].\n",
      "Accuracy: 1.000.\n",
      "10th fold with class distribution [241 143].\n",
      "Accuracy: 0.929.\n",
      "Mean accuracy: 0.948 +/- 0.031.\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                         PCA(n_components=2),\n",
    "                         LogisticRegression())\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "# Straightforward - for each of the k folds, use the fold training set and evaluate on the fold test set\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    scores.append(pipe_lr.score(X_train[test], y_train[test]))\n",
    "    print(f\"{k + 1}th fold with class distribution {np.bincount(y_train[train])}.\")\n",
    "    print(f\"Accuracy: {scores[-1]:.3f}.\")\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.97674419 0.97674419 0.90697674 0.95348837 0.97674419 0.90697674\n",
      " 0.92857143 0.92857143 1.         0.92857143]\n",
      "Mean accuracy: 0.948 +/- 0.031.\n"
     ]
    }
   ],
   "source": [
    "# This can all be done within sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=10, n_jobs=-1) # n_jobs=-1 parallelizes over all available CPUs\n",
    "print(f\"CV accuracy scores: {scores}\")\n",
    "print(f\"Mean accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataexercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
